---
title: "O-PLS/-DA Modeling"
output:
  html_document:
    keep_md: yes
---

Load data set, and set model x and y.
```{r,message=FALSE, warning=FALSE}
#load library now to prevent loading messages
Sys.setenv(ALLOW_WGCNA_THREADS=1)
suppressPackageStartupMessages(library(WGCNA)) # so annoying

#data
data(mtcars)

#X
pls.data<-mtcars[,-1]
#y, mpg
pls.y<-mtcars[,1,drop=F]

#make model
opls.results<-make.OSC.PLS.model(pls.y,pls.data,
						comp=2,
						OSC.comp=1, 
						validation = "LOO", 
						cv.scale = TRUE,
						train.test.index=NULL,
						progress=FALSE)				
```

Get 2 latent variables (LVs) and 1 orthogonal LV model stats.
```{r,message=FALSE, warning=FALSE}
#extra results as some LV and OSC and print model stats
final.opls.results<-get.OSC.model(obj=opls.results,OSC.comp=1)		
(opls.model.text<-data.frame("Xvar"=c(0,round(cumsum(final.opls.results$Xvar)*100,2)),"Q2"=final.opls.results$Q2,"RMSEP"= final.opls.results$RMSEP)	)
```

Predict mpg values for held out car data and calculate test error (RMSEP).
```{r,message=FALSE, warning=FALSE}
#train/test index 2/3 train and 1/3 test
train.test.index <- test.train.split(nrow(pls.data), n = 1) 

#fit model 
mods<-make.OSC.PLS.model(pls.y,pls.data,
						comp=2,
						OSC.comp=1, 
						validation = "LOO", 
						cv.scale = TRUE,
						train.test.index=train.test.index,
						progress=FALSE)	

#view predictions for test data
final.opls.results2<-get.OSC.model(obj=mods,OSC.comp=1)	
fitted<-final.opls.results2$predicted.Y
(RMSEP<-(.MSEP(actual=pls.y[train.test.index=="test",],pred=fitted))^.5)
```

Carry out 100 rounds of training and testing cross-validation and get model performance summary.
```{r,message=FALSE, warning=FALSE}
#train/test index 100 rounds
train.test.index <- test.train.split(nrow(pls.data), n = 100) 
multi.train.test<-OSC.PLS.train.test(pls.data = pls.data, pls.y = pls.y, train.test.index, comp = mods$total.LVs[1], OSC.comp = max(mods$OSC.LVs), cv.scale = mods$model.description$cv.scale, progress = FALSE) # ...
multi.train.test$summary
```

Carry out permutation testing and calculate random chance statistics (null model).
```{r,message=FALSE, warning=FALSE}
multi.permute<-permute.OSC.PLS.train.test(pls.data = pls.data, pls.y = pls.y, perm.n = 100, comp = mods$total.LVs[1], OSC.comp=max(mods$OSC.LVs), progress = FALSE, train.test.index = train.test.index)
```

Compare model statistical distrubutions to permuted model performance and calculate proportion of times real model was better then permuted model as a p-value.
```{r,message=FALSE, warning=FALSE}
#compare actual to permuted model performance
(model.validation<-OSC.validate.model(model = mods, perm = multi.permute, train = multi.train.test,test="perm.test"))
```

Carry out a single round of feature selection select top 4 features and plot results.
```{r,message=FALSE, warning=FALSE}
#feature selection
opts<-PLS.feature.select(pls.data,pls.scores=final.opls.results$scores[,][,1,drop=F],pls.loadings=final.opls.results$loadings[,][,1,drop=F],pls.weight=final.opls.results$loadings[,][,1,drop=F],plot=FALSE,p.value=0.1,FDR=TRUE,cut.type="number",top=4,separate=FALSE)
# make s-plot plus
plot.S.plot(obj=opts,return="all")
```

Calculate and compare performance statistics for included and excluded feature models.
```{r,message=FALSE, warning=FALSE}
optim<-optimize.OPLS.feature.select(model=opls.results,feature.subset=opts$combined.selection,permute=TRUE,train.test.index,progress=FALSE,test="perm.test") 
cbind(model=c(rep(c("model","permuted","p-value"),2),"p.value"),optim$summary)
```

Get model stats for decreasing number of model variables using full model loadings calculated above as a gradient.
```{r,message=FALSE, warning=FALSE}
#optimize model feature selections 
filter<-seq(3,ncol(pls.data)-3) # number of variables to keep
res<-multi.OPLS.feature.select(model=opls.results,filter=filter,plot=FALSE,OPLSDA=TRUE,train.test.index=train.test.index, test="perm.test", progress=FALSE) # use full model without training split as input
plot.multi.OPLS.feature.select(res,objects=c("RMSEP","Q2")) # view results
best.OPLS.features(res)[,1:5] # extract best model
```


