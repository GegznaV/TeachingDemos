Orthogonal Partial Least Squares (OPLS) 
========================================================

#### This is an example of OPLS modeling in R. See here for [more OPLS options](https://raw.github.com/dgrapov/devium/master/R/Devium%20PLS%20%20and%20OPLS.r) or try [PLS](http://cran.r-project.org/web/packages/pls/index.html).


```{r,include=FALSE,}
source("http://pastebin.com/raw.php?i=UyDBTA57") # source Devium
```

#### Generate some random data and Y's.
```{r}
set.seed(1234)
data<-matrix(rnorm(10000,0,1),nrow=100, ncol=100)
simple.y<-matrix(rep(1:2,50),,1)
complex.y<-matrix(sample(1:2,400,replace=T),,4)
```

#### Make exploratory model. Fit 10 latent variable (LVs) and 10 orthogonal latent variables (OLVs). 
```{r,hide=TRUE,message=FALSE}
#scale data 
scaled.data<-data.frame(scale(data,scale=T,center=T)) 

comp<-ocomp<-5 # maximum number of latent variables (LVs)
pls.y<-simple.y

mods1<-OSC.correction(progress=FALSE,pls.y=pls.y,pls.data=scaled.data,comp=comp,OSC.comp=ocomp,validation = "LOO",method="oscorespls",cv.scale=T)
```


#### View root mean squared error of prediction for various number of OLV models. Note X-axis reffers to total number of OLVs not LVs, hence the start at 0.
```{r,message=FALSE}
plot.OSC.results(obj=mods1,plot="RMSEP",groups=group)
```

#### View scores for various models.
```{r,message=FALSE}
#create factor to visualize groups
group<-factor(join.columns(pls.y))#visualize levels of y 
plot.OSC.results(obj=mods1,plot="scores",groups=group)
```

#### View variable loadings for various models.
```{r,message=FALSE}
#create factor to visualize groups
plot.OSC.results(obj=mods1,plot="loadings")
```


#### Get optimal LV/OLV suggestions. This becaomes very handy with multiple Ys.
```{r,hide=TRUE}
#fit 1:limit LV/OLV models to overview optimal LV and OLV
optimal.model<-optimize.OPLS(max.LV=comp, # max LV
  						tolerance =0.01, #tolerance for accepting higher error models but which are simpler
							pls.y=pls.y,pls.data=scaled.data, # y and data
							validation = "LOO",method="oscorespls",cv.scale=F,# see pls for theses options
							progress=FALSE) # see pls for theses options
```

#### View optimization suggestions.
```{r}
optimal.model

```
##### ```tolerance``` is used to accept higher RMSEP but simpler models.

#### Build optimized model based on optimal.model suggestions.
```{r,hide=TRUE}
mods1<-OSC.correction(progress=FALSE,pls.y=pls.y,pls.data=scaled.data,comp=optimal.model$LV,OSC.comp=optimal.model$OLV,validation = "LOO",method="oscorespls",cv.scale=T)
```

#### Get all model information.
```{r}
final<-get.OSC.model(obj=mods1,OSC.comp=optimal.model$OLV) 
```


#### View model scores.
```{r}
group<-factor(join.columns(pls.y))#visualize levels of y 
plot.PLS.results(obj=final,plot="scores",groups=group)
```

#### The next step for modeling would be to validate, but I will instead show complex. y modeling.

#### Complex multiple column Y.
```{r,hide=TRUE}
# make exploratory model to determine orthogonal LV (OLV) number 
comp<-6 # maximum number of latent variables (LVs)
pls.y<-complex.y
#fit 1:limit LV/OLV models to overview optimal LV and OLV
optimal.model<-optimize.OPLS(max.LV=comp, # max LV
  						tolerance =0.01, #tolerance for accepting higher error models but which are simpler
							pls.y=pls.y,pls.data=scaled.data, # y and data
							validation = "LOO",method="oscorespls",cv.scale=F,# see pls for theses options
							progress=FALSE)  # see pls for theses options
```

#### View suggestions.
```{r}
optimal.model
```

#### Build optimized model and plot scores.
```{r,hide=TRUE}
mods1<-OSC.correction(progress=FALSE,pls.y=pls.y,pls.data=scaled.data,comp=optimal.model$LV,OSC.comp=optimal.model$OLV,validation = "LOO",method="oscorespls",cv.scale=T)
final<-get.OSC.model(obj=mods1,OSC.comp=optimal.model$OLV) # get all model information

#view model scores
group<-factor(join.columns(pls.y))#visualize levels of y 
plot.PLS.results(obj=final,plot="scores",groups=group)
```

#### An alternative to modeling a multiple Ys is to define a single Y based on the multiple columns. This will try to organize all group scores in one dimension (LV1).
```{r,hide=TRUE}
pls.y<-matrix(as.numeric(as.factor(join.columns(complex.y))),,1) # create numeric representation
#fit 1:limit LV/OLV models to overview optimal LV and OLV
optimal.model<-optimize.OPLS(max.LV=comp, # max LV
  						tolerance =0.01, #tolerance for accepting higher error models but which are simpler
							pls.y=pls.y,pls.data=scaled.data, # y and data
							validation = "LOO",method="oscorespls",cv.scale=F,# see pls for theses options
							progress=FALSE) 
```

#### View suggestions.
```{r}
optimal.model
# currently single LV models will cause an error so limit LV minimium to 2
if(optimal.model$LV==1){optimal.model$LV<-2}
```
#### Build optimized model based on optimal.model suggestions.
```{r,hide=TRUE}
mods1<-OSC.correction(progress=FALSE,pls.y=pls.y,pls.data=scaled.data,comp=optimal.model$LV,OSC.comp=optimal.model$OLV,validation = "LOO",method="oscorespls",cv.scale=T)
final<-get.OSC.model(obj=mods1,OSC.comp=optimal.model$OLV) # get all model information
```

#### View model scores.
```{r}
group<-factor(join.columns(pls.y))#visualize levels of y 
plot.PLS.results(obj=final,plot="scores",groups=group) 
```

